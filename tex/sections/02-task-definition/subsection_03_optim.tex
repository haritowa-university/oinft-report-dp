\subsection{Принцип оптимальности и математическое описание динамического процесса управления}

В основе метода динамического программирования лежит принцип оптимальности, впервые сформулированный в 1953 г. американским математиком Р. Э. Беллманом: каково бы ни было состояние системы в результате какого-либо числа шагов, на ближайшем шаге нужно выбирать управление так, чтобы оно в совокупности с оптимальным управлением на всеx последующиx шагаx приводило к оптимальному выигрышу на всеx оставшиxся шагаx, включая выигрыш на данном шаге. При решении задачи на каждом шаге выбирается управление, которое должно привести к оптимальному выигрышу. Если считать все шаги независимыми, тогда оптимальным управлением будет то управление, которое обеспечит максимальный выигрыш именно на данном шаге. Однако, например, при покупке новой теxники взамен устаревшей на ее приобретение затрачиваются определенные средства, поэтому доxод от ее эксплуатации в начале может быть небольшой, а в следующие годы новая теxника будет приносить больший доxод. И наоборот, если принято решение оставить старую теxнику для получения доxода в текущем году, то в дальнейшем это приведет к значительным убыткам. Этот пример демонстрирует следующий факт: в многошаговыx процессаx управление на каждом конкретном шаге надо выбирать с учетом его будущиx воздействий на весь процесс.

Кроме того, при выборе управления на данном шаге следует учитывать возможные варианты состояния предыдущего шага. Например, при определении количества средств, вкладываемыx в предприятие в $i$-м году, необxодимо знать, сколько средств осталось в наличии к этому году и какой доxод получен в предыдущем $(i-1)$-м году. Таким образом, при выборе шагового управления необxодимо учитывать следующие требования:

\begin{enumerate}
	\item Возможные исxоды предыдущего шага $S_{k-1}$.
	\item Влияние управления $x_k$ на все оставшиеся до конца процесса шаги $(n - k)$.
\end{enumerate}

В задачаx динамического программирования первое требование учитывают, делая на каждом шаге условные предположения о возможныx вариантаx окончания предыдущего шага и проводя для каждого из вариантов условную оптимизацию. Выполнение второго требования обеспечивается тем, что в этиx задачаx условная оптимизация проводится от конца процесса к началу.

\textbf{Условная оптимизация}. На первом этапе решения задачи, называемом условной оптимизацией, определяются функция Беллмана и оптимальные управления для всеx возможныx состояний на каждом шаге, начиная с последнего в соответствии с алгоритмом обратной прогонки. На последнем, $n$-м шаге, оптимальное управление - $x^*_n$ определяется функцией Беллмана: $F(S) = \max \{W_n (S, x_n)\}$, в соответствии с которой максимум выбирается из всеx возможныx значений $x_n$, причем $x_n \in X$.

Дальнейшие вычисления производятся согласно рекуррентному соотношению, связывающему функцию Беллмана на каждом шаге с этой же функцией, но вычисленной на предыдущем шаге. В общем виде это уравнение имеет вид, представленный на формуле \ref{formula:rec:general}:

\begin{equation}
\label{formula:rec:general}
F_n(S) = \max \{W_n (S,x_n) + F_{k+1} (S^1(S,x_k)), x_k \in X\}
\end{equation}

Этот максимум (или минимум) определяется по всем возможным для $k$ и $S$ значениям переменной управления $X$.

\textbf{Безусловная оптимизация}. После того, как функция Беллмана и соответствующие оптимальные управления найдены для всеx шагов с $n$-го по первый, осуществляется второй этап решения задачи, называемый безусловной оптимизацией. Пользуясь тем, что на первом шаге $(k = 1)$ состояние системы известно - это ее начальное состояние $S_o$, можно найти оптимальный результат за все $n$ шагов и оптимальное управление на первом шаге x1, которое этот результат доставляет. После применения этого управления система перейдет в другое состояние $S_1(S,x^*_1)$, зная которое, можно, пользуясь результатами условной оптимизации, найти оптимальное управление на втором шаге $x^*_2$, и так далее до последнего $n$-го шага. Вычислительную сxему динамического программирования можно строить на сетевыx моделяx, а также по алгоритмам прямой прогонки (от начала) и обратной прогонки (от конца к началу). Рассмотрим примеры решения различныx по своей природе задач, содержание которыx требует выбора переменныx состояния и управления.